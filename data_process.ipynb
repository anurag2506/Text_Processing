{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import textstat\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/anuragprasad/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Creating a set of stop words that is removed from the entire corpus of text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    pos_words = file.read().splitlines()\n",
    "\n",
    "with open('negative-words.txt', 'r') as file:\n",
    "    neg_words = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['positive', 'negative']\n",
    "values = [pos_words, neg_words]\n",
    "master_dict = dict(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Input.xlsx - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for file in os.listdir('scraped_articles'):\n",
    "\n",
    "    with open(f'scraped_articles/{file}', 'r') as file:\n",
    "        article = file.read()\n",
    "    content.append(article)\n",
    "data['content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates metrics 1-4:\n",
    "def metrics_1_4(data):\n",
    "    for i in range(len(data)):\n",
    "        text_tokens = word_tokenize(data.iloc[i]['content'])\n",
    "        filtered_words = [w for w in text_tokens]\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for word in filtered_text.split(' '):\n",
    "            if word in pos_words:\n",
    "                pos_score += 1\n",
    "            elif word in neg_words:\n",
    "                neg_score += 1\n",
    "\n",
    "        neg_score *= -1\n",
    "        data.at[i, 'POSITIVE SCORE'] = pos_score\n",
    "        data.at[i, 'NEGATIVE SCORE'] = neg_score\n",
    "        \n",
    "        total_score = pos_score + neg_score\n",
    "        data.at[i, 'POLARITY SCORE'] = (pos_score - neg_score)/(total_score + 0.000001)\n",
    "        data.at[i, 'SUBJECTIVITY SCORE'] = total_score/(len(filtered_words) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds all the attributes related to fog index and metrics 5-10\n",
    "def metrics_5_10(data):\n",
    "    for i in range(len(data)):\n",
    "        article_text = data.iloc[i]['content']\n",
    "        text_tokens = word_tokenize(article_text)\n",
    "        text_words = [word for word in text_tokens if word.strip() and word.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', article_text)\n",
    "        sentences = [s for s in sentences if s.strip()]\n",
    "\n",
    "       # Finding complex words with more than 1 syllable using textstat library\n",
    "        complex_words = [word for word in text_tokens if textstat.syllable_count(word)>1]\n",
    "        \n",
    "        # Average sentence length involved calculating the extra characters, punctuation as well\n",
    "        avg_sentence_length = len(article_text)/len(sentences)\n",
    "        complex_word_percent = len(complex_words)/len(text_tokens)\n",
    "        avg_words_per_sentence = len(text_words)/len(sentences)\n",
    "\n",
    "        data.at[i,'AVG SENTENCE LENGTH'] = avg_sentence_length\n",
    "        data.at[i, 'PERCENTAGE OF COMPLEX WORDS'] = complex_word_percent\n",
    "        data.at[i, 'FOG INDEX'] = 0.4*(avg_sentence_length+complex_word_percent)\n",
    "        data.at[i, 'AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence\n",
    "        data.at[i, 'COMPLEX WORD COUNT'] = len(complex_words)\n",
    "\n",
    "        # Count of cleaned text (without stop words):\n",
    "        filtered_words = [word for word in text_words if word not in stop_words]\n",
    "        data.at[i, 'WORD COUNT'] = len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(words):\n",
    "    count_char = 0\n",
    "    for word in words:\n",
    "        count_char+= len(word)\n",
    "    return count_char/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        count += max(1, textstat.syllable_count(word))\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for 11-13:\n",
    "def metrics_11_13(data):\n",
    "    for i in range(len(data)):\n",
    "        article_text = data.iloc[i]['content']\n",
    "        text_tokens = word_tokenize(article_text)\n",
    "        text_words = [word for word in text_tokens if word.strip() and word.isalpha()]\n",
    "        syllables_in_text = count_syllables(text_words) \n",
    "\n",
    "        # Stores the average number of syllables per words\n",
    "        data.at[i, 'SYLLABLE PER WORD'] = syllables_in_text/len(text_words)\n",
    "\n",
    "\n",
    "        pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "        pronoun_count = sum(1 for word in text_words if word in pronouns)\n",
    "        data.at[i, 'PERSONAL PRONOUNS'] = pronoun_count\n",
    "\n",
    "        # Using the function for avg-word length:\n",
    "        data.at[i, 'AVG WORD LENGTH'] = avg_word_length(text_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1_4(data = data)\n",
    "metrics_5_10(data = data)\n",
    "metrics_11_13(data= data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>content</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POLARITY_SCORE</th>\n",
       "      <th>SUBJECTIVITY_SCORE</th>\n",
       "      <th>AVG_SENTENCE_LENGTH</th>\n",
       "      <th>PERCENTAGE_COMPLEX_WORDS</th>\n",
       "      <th>FOG_INDEX</th>\n",
       "      <th>AVG_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORD_COUNT</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "      <th>SYLLABLE_COUNT_PER_WORD</th>\n",
       "      <th>PERSONAL_PRONOUNS</th>\n",
       "      <th>AVERAGE_WORD_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>ROAS Dashboard for Campaign-Wise Google Ads Bu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.999996</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>101.416667</td>\n",
       "      <td>0.435855</td>\n",
       "      <td>40.741009</td>\n",
       "      <td>14.416667</td>\n",
       "      <td>265.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1.730250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.308285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>Analyzing the Impact of Positive Emotions and ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>142.115385</td>\n",
       "      <td>0.526802</td>\n",
       "      <td>57.056875</td>\n",
       "      <td>16.769231</td>\n",
       "      <td>285.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.174312</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.442661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>Enhancing Front-End Features and Functionality...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.799999</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>125.340909</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>50.276562</td>\n",
       "      <td>19.318182</td>\n",
       "      <td>354.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.623529</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.855294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>Google Local Service Ads Missed Calls and Mess...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>36.215385</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>Splitting of Songs into its Vocals and Instrum...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>30.218182</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "      <td>Traction Dashboards of Marketing Campaigns and...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.999997</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>123.200000</td>\n",
       "      <td>0.390428</td>\n",
       "      <td>49.436171</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>155.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.654391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.235127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "      <td>Google LSA API Data Automation and Dashboardin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>28.680000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "      <td>Healthcare Data Analysis - Blackcoffer Insight...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>18.999981</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>95.482759</td>\n",
       "      <td>0.402041</td>\n",
       "      <td>38.353920</td>\n",
       "      <td>14.758621</td>\n",
       "      <td>197.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1.621495</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.843458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "      <td>Google Local Service Ads (LSA) Data Warehouse ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>181.900000</td>\n",
       "      <td>0.460208</td>\n",
       "      <td>72.944083</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>133.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.797665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.494163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "      <td>Enhancing Data Collection for Research Institu...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>121.774194</td>\n",
       "      <td>0.516068</td>\n",
       "      <td>48.916105</td>\n",
       "      <td>13.387097</td>\n",
       "      <td>273.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.110843</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.440964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                                URL  \\\n",
       "0    Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1    Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2    Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3    Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4    Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "..               ...                                                ...   \n",
       "142  Netclan20241159  https://insights.blackcoffer.com/population-an...   \n",
       "143  Netclan20241160  https://insights.blackcoffer.com/google-lsa-ap...   \n",
       "144  Netclan20241161  https://insights.blackcoffer.com/healthcare-da...   \n",
       "145  Netclan20241162  https://insights.blackcoffer.com/budget-sales-...   \n",
       "146  Netclan20241163  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
       "\n",
       "                                               content  POSITIVE_SCORE  \\\n",
       "0    ROAS Dashboard for Campaign-Wise Google Ads Bu...             9.0   \n",
       "1    Analyzing the Impact of Positive Emotions and ...            11.0   \n",
       "2    Enhancing Front-End Features and Functionality...            12.0   \n",
       "3    Google Local Service Ads Missed Calls and Mess...             0.0   \n",
       "4    Splitting of Songs into its Vocals and Instrum...             0.0   \n",
       "..                                                 ...             ...   \n",
       "142  Traction Dashboards of Marketing Campaigns and...             2.0   \n",
       "143  Google LSA API Data Automation and Dashboardin...             0.0   \n",
       "144  Healthcare Data Analysis - Blackcoffer Insight...            10.0   \n",
       "145  Google Local Service Ads (LSA) Data Warehouse ...             4.0   \n",
       "146  Enhancing Data Collection for Research Institu...            16.0   \n",
       "\n",
       "     NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE  AVG_SENTENCE_LENGTH  \\\n",
       "0              -7.0        7.999996            0.003289           101.416667   \n",
       "1              -3.0        1.750000            0.014787           142.115385   \n",
       "2              -7.0        3.799999            0.004950           125.340909   \n",
       "3               0.0        0.000000            0.000000            90.000000   \n",
       "4               0.0        0.000000            0.000000            75.000000   \n",
       "..              ...             ...                 ...                  ...   \n",
       "142            -1.0        2.999997            0.002519           123.200000   \n",
       "143             0.0        0.000000            0.000000            71.000000   \n",
       "144            -9.0       18.999981            0.002041            95.482759   \n",
       "145             0.0        1.000000            0.013841           181.900000   \n",
       "146            -4.0        1.666667            0.022684           121.774194   \n",
       "\n",
       "     PERCENTAGE_COMPLEX_WORDS  FOG_INDEX  AVG_WORDS_PER_SENTENCE  \\\n",
       "0                    0.435855  40.741009               14.416667   \n",
       "1                    0.526802  57.056875               16.769231   \n",
       "2                    0.350495  50.276562               19.318182   \n",
       "3                    0.538462  36.215385               12.000000   \n",
       "4                    0.545455  30.218182               10.000000   \n",
       "..                        ...        ...                     ...   \n",
       "142                  0.390428  49.436171               17.650000   \n",
       "143                  0.700000  28.680000                9.000000   \n",
       "144                  0.402041  38.353920               14.758621   \n",
       "145                  0.460208  72.944083               25.700000   \n",
       "146                  0.516068  48.916105               13.387097   \n",
       "\n",
       "     COMPLEX_WORD_COUNT  WORD_COUNT  SYLLABLE_COUNT_PER_WORD  \\\n",
       "0                 265.0       405.0                 1.730250   \n",
       "1                 285.0       339.0                 2.174312   \n",
       "2                 354.0       496.0                 1.623529   \n",
       "3                   7.0        11.0                 1.916667   \n",
       "4                   6.0         6.0                 1.900000   \n",
       "..                  ...         ...                      ...   \n",
       "142               155.0       238.0                 1.654391   \n",
       "143                 7.0         8.0                 2.333333   \n",
       "144               197.0       272.0                 1.621495   \n",
       "145               133.0       196.0                 1.797665   \n",
       "146               273.0       323.0                 2.110843   \n",
       "\n",
       "     PERSONAL_PRONOUNS  AVERAGE_WORD_LENGTH  \n",
       "0                  1.0             5.308285  \n",
       "1                  2.0             6.442661  \n",
       "2                  7.0             4.855294  \n",
       "3                  0.0             6.333333  \n",
       "4                  0.0             6.300000  \n",
       "..                 ...                  ...  \n",
       "142                5.0             5.235127  \n",
       "143                0.0             6.666667  \n",
       "144               13.0             4.843458  \n",
       "145                0.0             5.494163  \n",
       "146                3.0             6.440964  \n",
       "\n",
       "[147 rows x 16 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>content</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POLARITY_SCORE</th>\n",
       "      <th>SUBJECTIVITY_SCORE</th>\n",
       "      <th>AVG_SENTENCE_LENGTH</th>\n",
       "      <th>PERCENTAGE_COMPLEX_WORDS</th>\n",
       "      <th>FOG_INDEX</th>\n",
       "      <th>AVG_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORD_COUNT</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>ROAS Dashboard for Campaign-Wise Google Ads Bu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.999996</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>101.416667</td>\n",
       "      <td>0.435855</td>\n",
       "      <td>40.741009</td>\n",
       "      <td>14.416667</td>\n",
       "      <td>265.0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>Analyzing the Impact of Positive Emotions and ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>142.115385</td>\n",
       "      <td>0.526802</td>\n",
       "      <td>57.056875</td>\n",
       "      <td>16.769231</td>\n",
       "      <td>285.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>Enhancing Front-End Features and Functionality...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.799999</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>125.340909</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>50.276562</td>\n",
       "      <td>19.318182</td>\n",
       "      <td>354.0</td>\n",
       "      <td>496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>Google Local Service Ads Missed Calls and Mess...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>36.215385</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>Splitting of Songs into its Vocals and Instrum...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>30.218182</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "\n",
       "                                             content  POSITIVE_SCORE  \\\n",
       "0  ROAS Dashboard for Campaign-Wise Google Ads Bu...             9.0   \n",
       "1  Analyzing the Impact of Positive Emotions and ...            11.0   \n",
       "2  Enhancing Front-End Features and Functionality...            12.0   \n",
       "3  Google Local Service Ads Missed Calls and Mess...             0.0   \n",
       "4  Splitting of Songs into its Vocals and Instrum...             0.0   \n",
       "\n",
       "   NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE  AVG_SENTENCE_LENGTH  \\\n",
       "0            -7.0        7.999996            0.003289           101.416667   \n",
       "1            -3.0        1.750000            0.014787           142.115385   \n",
       "2            -7.0        3.799999            0.004950           125.340909   \n",
       "3             0.0        0.000000            0.000000            90.000000   \n",
       "4             0.0        0.000000            0.000000            75.000000   \n",
       "\n",
       "   PERCENTAGE_COMPLEX_WORDS  FOG_INDEX  AVG_WORDS_PER_SENTENCE  \\\n",
       "0                  0.435855  40.741009               14.416667   \n",
       "1                  0.526802  57.056875               16.769231   \n",
       "2                  0.350495  50.276562               19.318182   \n",
       "3                  0.538462  36.215385               12.000000   \n",
       "4                  0.545455  30.218182               10.000000   \n",
       "\n",
       "   COMPLEX_WORD_COUNT  WORD_COUNT  \n",
       "0               265.0       405.0  \n",
       "1               285.0       339.0  \n",
       "2               354.0       496.0  \n",
       "3                 7.0        11.0  \n",
       "4                 6.0         6.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', \n",
    "                             'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', \n",
    "                             'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', \n",
    "                             ' AVG NUMBER OF WORDS PER SENTENCE',\n",
    "                              'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "                              'SYLLABLE PER WORD', 'PERSONAL PRONOUNS',\n",
    "                              'AVG WORD LENGTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
