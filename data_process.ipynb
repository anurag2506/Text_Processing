{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI and ML-Based YouTube Analytics and Content Creation Tool for Optimizing Subscriber Engagement and Content Strategy - Blackcoffer Insights\\nClient Background\\n\\nClient:A leading IT & tech firm in the USA\\n\\nIndustry Type:IT\\n\\nProducts & Services:IT Consulting, IT Support, SaaS, Marketing Strategy\\n\\nOrganization Size:10+\\n\\nThe Problem\\n\\nBuilding AI and ML based YouTube analytics and content creation tool that will help youtuber to understand their subscriber’s watching behaviour, help them in content research, creation and publication.\\n\\nOur Solution\\n\\nCreated a MERN stack web application and integrated AI models to helps youtuber to generated titles, descriptions, tags, hashtags, captions etc. Help them to check thumbnail quality, analysis on the videos using video auditor tool, analysis on comments using sentiments analysis, help to under their subscribers using churn predication AI model.\\n\\nSolution Architecture\\n\\nDeliverables\\n\\nWeb Applications\\n\\nSupports\\n\\nMaintenance\\n\\nFeature Enhancement\\n\\nTech Stack\\n\\nTools used\\n\\nVS code\\n\\nLanguage/techniques used\\n\\nReact.js\\n\\nExpress.js\\n\\nNode.js\\n\\nPython\\n\\nModels used\\n\\nPython libraries\\n\\nSkills used\\n\\nData scientise\\n\\nFull Stack developer\\n\\nDatabases used\\n\\nMongoDB\\n\\nWeb Cloud Servers used\\n\\nGoogle Cloud Platform\\n\\nProject Snapshots\\n\\nHome Page\\n\\nHome Page\\n\\nTool Page\\n\\nTool Page\\n\\nDashboard\\n\\nDashboard\\n\\nBlog Page\\n\\nBlog Page\\n\\nSingle Blog Post\\n\\nSingle Blog Post\\n\\nAbout Us\\n\\nAbout Us\\n\\nContact Us\\n\\nContact Us\\n\\nLogin Page\\n\\nLogin Page\\n\\nTitle and Description tool Page\\n\\nTitle and Description tool Page\\n\\nThumbnail Quality check tool\\n\\nThumbnail Quality check tool\\n\\nProject website url\\n\\nhttps://tubetool.ai\\n\\nSummarize\\n\\nSummarized: https://blackcoffer.com/\\n\\nThis project was done by the Blackcoffer Team, a Global IT Consulting firm.\\n\\nContact Details\\n\\nThis solution was designed and developed by Blackcoffer TeamHere are my contact details:Firm Name: Blackcoffer Pvt. Ltd.Firm Website: www.blackcoffer.comFirm Address: 4/2, E-Extension, Shaym Vihar Phase 1, New Delhi 110043Email: ajay@blackcoffer.comSkype: asbidyarthyWhatsApp: +91 9717367468Telegram: @asbidyarthy\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('scraped_articles/Netclan20241017.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/anuragprasad/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Creating a set of stop words that is removed from the entire corpus of text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    pos_words = file.read().splitlines()\n",
    "\n",
    "with open('negative-words.txt', 'r') as file:\n",
    "    neg_words = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['positive', 'negative']\n",
    "values = [pos_words, neg_words]\n",
    "master_dict = dict(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Input.xlsx - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for file in os.listdir('scraped_articles'):\n",
    "\n",
    "    with open(f'scraped_articles/{file}', 'r') as file:\n",
    "        article = file.read()\n",
    "    content.append(article)\n",
    "data['content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_scores(data):\n",
    "    for i in range(len(data)):\n",
    "        text_tokens = word_tokenize(data.iloc[i]['content'])\n",
    "        filtered_words = [w for w in text_tokens if not w in stop_words]\n",
    "        filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for word in filtered_text.split(' '):\n",
    "            if word in pos_words:\n",
    "                pos_score += 1\n",
    "            elif word in neg_words:\n",
    "                neg_score += 1\n",
    "\n",
    "        neg_score *= -1\n",
    "        data.at[i, 'POSITIVE_SCORE'] = pos_score\n",
    "        data.at[i, 'NEGATIVE_SCORE'] = neg_score\n",
    "        \n",
    "        total_score = pos_score + neg_score\n",
    "        data.at[i, 'POLARITY_SCORE'] = (pos_score - neg_score)/(total_score + 0.000001)\n",
    "        data.at[i, 'SUBJECTIVITY_SCORE'] = total_score/(len(filtered_words) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds all the attributes related to fog index\n",
    "def fog_index(data):\n",
    "    for i in range(len(data)):\n",
    "        article_text = data.iloc[i]['CONTENT']\n",
    "        text_tokens = word_tokenize(article_text)\n",
    "        text_words = [word for word in text_tokens if word.strip() and word.isalpha()]\n",
    "        sentences = re.split(r'[.!?]+', article_text)\n",
    "        sentences = [s for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "        complex_words = [word for word in text_tokens if textstat]\n",
    "\n",
    "        data.at[i,'AVG_SENTENCE_LENGTH'] = len(text_words)/len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "give_scores(data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>content</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POLARITY_SCORE</th>\n",
       "      <th>SUBJECTIVITY_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>ROAS Dashboard for Campaign-Wise Google Ads Bu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.999996</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>Analyzing the Impact of Positive Emotions and ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.018018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>Enhancing Front-End Features and Functionality...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.799999</td>\n",
       "      <td>0.007622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>Google Local Service Ads Missed Calls and Mess...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>Splitting of Songs into its Vocals and Instrum...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "\n",
       "                                             content  POSITIVE_SCORE  \\\n",
       "0  ROAS Dashboard for Campaign-Wise Google Ads Bu...             9.0   \n",
       "1  Analyzing the Impact of Positive Emotions and ...            11.0   \n",
       "2  Enhancing Front-End Features and Functionality...            12.0   \n",
       "3  Google Local Service Ads Missed Calls and Mess...             0.0   \n",
       "4  Splitting of Songs into its Vocals and Instrum...             0.0   \n",
       "\n",
       "   NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE  \n",
       "0            -7.0        7.999996            0.004049  \n",
       "1            -3.0        1.750000            0.018018  \n",
       "2            -7.0        3.799999            0.007622  \n",
       "3             0.0        0.000000            0.000000  \n",
       "4             0.0        0.000000            0.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', \n",
    "                             'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', \n",
    "                             'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', \n",
    "                             ' AVG NUMBER OF WORDS PER SENTENCE',\n",
    "                              'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "                              'SYLLABLE PER WORD', 'PERSONAL PRONOUNS',\n",
    "                              'AVG WORD LENGTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
